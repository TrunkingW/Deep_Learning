{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TB=0\n",
    "TE=3389\n",
    "INPUT_SIZE=7\n",
    "OUTPUT_SIZE=1\n",
    "BATCH_SIZE=1\n",
    "TIME_STEPS=1\n",
    "CELL_SIZE=7\n",
    "HIDD=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('test.csv') \n",
    "df=pd.read_csv(f)     \n",
    "data=df.iloc[:,2:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_data(train_begin=TB,train_end=TE):\n",
    "    global train_mean, train_std\n",
    "    data_train=data[train_begin:train_end]\n",
    "    train_mean=np.mean(data_train,axis=0)\n",
    "    train_std=np.std(data_train,axis=0)\n",
    "    normalized_train_data=(data_train-train_mean)/train_std\n",
    "    train_x = normalized_train_data[:,:7]\n",
    "    train_y = normalized_train_data[:,7,np.newaxis]\n",
    "    return train_x[:, np.newaxis], train_y[:, np.newaxis]\n",
    "train_x, train_y=get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_data(test_begin=TE):\n",
    "    global test_mean, test_std\n",
    "    data_test=data[test_begin:]\n",
    "    test_mean=np.mean(data_test,axis=0)\n",
    "    test_std=np.std(data_test,axis=0)\n",
    "    test_data=(data_test-test_mean)/test_std\n",
    "    test_x=test_data[:,:7]\n",
    "    test_y=test_data[:,7,np.newaxis]\n",
    "    return test_x[:, np.newaxis], test_y[:, np.newaxis]\n",
    "test_x, test_y=get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(batch_input_shape=(1, 1, 7), return_sequences=True, stateful=True, units=7)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28s - loss: 0.1953\n",
      "Epoch 2/20\n",
      "23s - loss: 0.0884\n",
      "Epoch 3/20\n",
      "20s - loss: 0.0757\n",
      "Epoch 4/20\n",
      "19s - loss: 0.0731\n",
      "Epoch 5/20\n",
      "20s - loss: 0.0700\n",
      "Epoch 6/20\n",
      "21s - loss: 0.0698\n",
      "Epoch 7/20\n",
      "21s - loss: 0.0732\n",
      "Epoch 8/20\n",
      "21s - loss: 0.0750\n",
      "Epoch 9/20\n",
      "24s - loss: 0.0800\n",
      "Epoch 10/20\n",
      "21s - loss: 0.0794\n",
      "Epoch 11/20\n",
      "26s - loss: 0.0731\n",
      "Epoch 12/20\n",
      "25s - loss: 0.0723\n",
      "Epoch 13/20\n",
      "24s - loss: 0.0765\n",
      "Epoch 14/20\n",
      "25s - loss: 0.0664\n",
      "Epoch 15/20\n",
      "22s - loss: 0.0632\n",
      "Epoch 16/20\n",
      "24s - loss: 0.0705\n",
      "Epoch 17/20\n",
      "24s - loss: 0.0636\n",
      "Epoch 18/20\n",
      "23s - loss: 0.0661\n",
      "Epoch 19/20\n",
      "22s - loss: 0.0641\n",
      "Epoch 20/20\n",
      "24s - loss: 0.0645\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# build a LSTM RNN\n",
    "model.add(LSTM(\n",
    "    batch_input_shape=(BATCH_SIZE, TIME_STEPS, INPUT_SIZE),       # Or: input_dim=INPUT_SIZE, input_length=TIME_STEPS,\n",
    "    output_dim=CELL_SIZE,\n",
    "    return_sequences=True,      # True: output at all steps. False: output as last step.\n",
    "    stateful=True              # True: the final state of batch1 is feed into the initial state of batch2\n",
    "))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    HIDD,\n",
    "    return_sequences=True,\n",
    "    stateful=True\n",
    "))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "# add output layer\n",
    "\n",
    "model.add(TimeDistributed(Dense(OUTPUT_SIZE)))\n",
    "#adam = Adam(LR)\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "train_history=model.fit(train_x, train_y, batch_size=BATCH_SIZE, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3374/3389 [============================>.] - ETA: 0s0.117526745231\n"
     ]
    }
   ],
   "source": [
    "trainScore = model.evaluate(train_x, train_y, batch_size=BATCH_SIZE, verbose=1)\n",
    "print(trainScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/100 [=========================>....] - ETA: 0s[[[-0.71110803]]\n",
      "\n",
      " [[-1.64495671]]\n",
      "\n",
      " [[-1.7818979 ]]\n",
      "\n",
      " [[-1.84635365]]\n",
      "\n",
      " [[-1.75300658]]\n",
      "\n",
      " [[-1.90383935]]\n",
      "\n",
      " [[-1.59853685]]\n",
      "\n",
      " [[-1.86911213]]\n",
      "\n",
      " [[-1.69710052]]\n",
      "\n",
      " [[-1.64845717]]\n",
      "\n",
      " [[-1.64377809]]\n",
      "\n",
      " [[-1.57612956]]\n",
      "\n",
      " [[-1.42453754]]\n",
      "\n",
      " [[-1.47983825]]\n",
      "\n",
      " [[-1.48395658]]\n",
      "\n",
      " [[-1.30504274]]\n",
      "\n",
      " [[-1.23808229]]\n",
      "\n",
      " [[-1.16105521]]\n",
      "\n",
      " [[-1.16746306]]\n",
      "\n",
      " [[-1.00741196]]\n",
      "\n",
      " [[-0.88072151]]\n",
      "\n",
      " [[-0.78170878]]\n",
      "\n",
      " [[-0.75625175]]\n",
      "\n",
      " [[-0.75635386]]\n",
      "\n",
      " [[-0.73214799]]\n",
      "\n",
      " [[-0.71543211]]\n",
      "\n",
      " [[-0.76788473]]\n",
      "\n",
      " [[-0.87942767]]\n",
      "\n",
      " [[-0.84524369]]\n",
      "\n",
      " [[-0.79201877]]\n",
      "\n",
      " [[-0.72047752]]\n",
      "\n",
      " [[-0.71286452]]\n",
      "\n",
      " [[-0.56282932]]\n",
      "\n",
      " [[-0.57323885]]\n",
      "\n",
      " [[-0.65201795]]\n",
      "\n",
      " [[-0.62251639]]\n",
      "\n",
      " [[-0.48528025]]\n",
      "\n",
      " [[-0.48055217]]\n",
      "\n",
      " [[-0.35127002]]\n",
      "\n",
      " [[-0.31739739]]\n",
      "\n",
      " [[-0.2866087 ]]\n",
      "\n",
      " [[-0.22638594]]\n",
      "\n",
      " [[-0.24146439]]\n",
      "\n",
      " [[-0.54537302]]\n",
      "\n",
      " [[-0.51617759]]\n",
      "\n",
      " [[-0.56766087]]\n",
      "\n",
      " [[-0.60870695]]\n",
      "\n",
      " [[-0.42395565]]\n",
      "\n",
      " [[-0.2214361 ]]\n",
      "\n",
      " [[ 0.16731505]]\n",
      "\n",
      " [[ 0.026235  ]]\n",
      "\n",
      " [[ 0.33233249]]\n",
      "\n",
      " [[ 0.28114942]]\n",
      "\n",
      " [[ 0.84100032]]\n",
      "\n",
      " [[ 0.84733945]]\n",
      "\n",
      " [[ 0.65340865]]\n",
      "\n",
      " [[ 0.73453885]]\n",
      "\n",
      " [[ 0.52760333]]\n",
      "\n",
      " [[ 0.59654307]]\n",
      "\n",
      " [[ 0.54670537]]\n",
      "\n",
      " [[ 0.61614043]]\n",
      "\n",
      " [[ 0.60992658]]\n",
      "\n",
      " [[ 0.46029058]]\n",
      "\n",
      " [[ 0.54841137]]\n",
      "\n",
      " [[ 0.92751783]]\n",
      "\n",
      " [[ 0.90388227]]\n",
      "\n",
      " [[ 1.10326982]]\n",
      "\n",
      " [[ 0.9242993 ]]\n",
      "\n",
      " [[ 1.04065526]]\n",
      "\n",
      " [[ 0.97633177]]\n",
      "\n",
      " [[ 1.06634402]]\n",
      "\n",
      " [[ 0.98474336]]\n",
      "\n",
      " [[ 0.90448171]]\n",
      "\n",
      " [[ 0.9398219 ]]\n",
      "\n",
      " [[ 1.01230979]]\n",
      "\n",
      " [[ 0.9662919 ]]\n",
      "\n",
      " [[ 1.16453993]]\n",
      "\n",
      " [[ 0.8393712 ]]\n",
      "\n",
      " [[ 0.85754609]]\n",
      "\n",
      " [[ 0.98068541]]\n",
      "\n",
      " [[ 1.08116448]]\n",
      "\n",
      " [[ 0.87852889]]\n",
      "\n",
      " [[ 0.99903995]]\n",
      "\n",
      " [[ 1.16454744]]\n",
      "\n",
      " [[ 1.02416968]]\n",
      "\n",
      " [[ 0.84252328]]\n",
      "\n",
      " [[ 0.8899138 ]]\n",
      "\n",
      " [[ 0.863015  ]]\n",
      "\n",
      " [[ 0.84534544]]\n",
      "\n",
      " [[ 0.86981004]]\n",
      "\n",
      " [[ 0.80014235]]\n",
      "\n",
      " [[ 0.9359023 ]]\n",
      "\n",
      " [[ 0.79059398]]\n",
      "\n",
      " [[ 0.77152485]]\n",
      "\n",
      " [[ 0.98655111]]\n",
      "\n",
      " [[ 0.94886529]]\n",
      "\n",
      " [[ 1.09074795]]\n",
      "\n",
      " [[ 1.06666994]]\n",
      "\n",
      " [[ 0.98231149]]\n",
      "\n",
      " [[ 0.90234441]]]\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict(test_x, batch_size=BATCH_SIZE,verbose=1)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 76.70241547]],\n",
       "\n",
       "       [[ 73.7711792 ]],\n",
       "\n",
       "       [[ 73.34133148]],\n",
       "\n",
       "       [[ 73.1390152 ]],\n",
       "\n",
       "       [[ 73.43202209]],\n",
       "\n",
       "       [[ 72.95857239]],\n",
       "\n",
       "       [[ 73.91688538]],\n",
       "\n",
       "       [[ 73.06758118]],\n",
       "\n",
       "       [[ 73.6075058 ]],\n",
       "\n",
       "       [[ 73.76018524]],\n",
       "\n",
       "       [[ 73.77487183]],\n",
       "\n",
       "       [[ 73.98721313]],\n",
       "\n",
       "       [[ 74.46304321]],\n",
       "\n",
       "       [[ 74.28945923]],\n",
       "\n",
       "       [[ 74.27653503]],\n",
       "\n",
       "       [[ 74.83812714]],\n",
       "\n",
       "       [[ 75.04830933]],\n",
       "\n",
       "       [[ 75.29008484]],\n",
       "\n",
       "       [[ 75.26997375]],\n",
       "\n",
       "       [[ 75.77235413]],\n",
       "\n",
       "       [[ 76.17002106]],\n",
       "\n",
       "       [[ 76.48081207]],\n",
       "\n",
       "       [[ 76.56071472]],\n",
       "\n",
       "       [[ 76.56039429]],\n",
       "\n",
       "       [[ 76.63637543]],\n",
       "\n",
       "       [[ 76.68884277]],\n",
       "\n",
       "       [[ 76.52420044]],\n",
       "\n",
       "       [[ 76.1740799 ]],\n",
       "\n",
       "       [[ 76.2813797 ]],\n",
       "\n",
       "       [[ 76.44844818]],\n",
       "\n",
       "       [[ 76.67300415]],\n",
       "\n",
       "       [[ 76.69690704]],\n",
       "\n",
       "       [[ 77.16784668]],\n",
       "\n",
       "       [[ 77.13516998]],\n",
       "\n",
       "       [[ 76.88789368]],\n",
       "\n",
       "       [[ 76.98049927]],\n",
       "\n",
       "       [[ 77.41126251]],\n",
       "\n",
       "       [[ 77.42610168]],\n",
       "\n",
       "       [[ 77.83190918]],\n",
       "\n",
       "       [[ 77.93822479]],\n",
       "\n",
       "       [[ 78.03487396]],\n",
       "\n",
       "       [[ 78.22389984]],\n",
       "\n",
       "       [[ 78.17657471]],\n",
       "\n",
       "       [[ 77.22264099]],\n",
       "\n",
       "       [[ 77.31427765]],\n",
       "\n",
       "       [[ 77.15267944]],\n",
       "\n",
       "       [[ 77.02384186]],\n",
       "\n",
       "       [[ 77.60375214]],\n",
       "\n",
       "       [[ 78.23944092]],\n",
       "\n",
       "       [[ 79.45968628]],\n",
       "\n",
       "       [[ 79.01685333]],\n",
       "\n",
       "       [[ 79.9776535 ]],\n",
       "\n",
       "       [[ 79.81699371]],\n",
       "\n",
       "       [[ 81.57430267]],\n",
       "\n",
       "       [[ 81.59420013]],\n",
       "\n",
       "       [[ 80.98547363]],\n",
       "\n",
       "       [[ 81.24013519]],\n",
       "\n",
       "       [[ 80.5905838 ]],\n",
       "\n",
       "       [[ 80.80698395]],\n",
       "\n",
       "       [[ 80.65054321]],\n",
       "\n",
       "       [[ 80.86849213]],\n",
       "\n",
       "       [[ 80.84899139]],\n",
       "\n",
       "       [[ 80.37930298]],\n",
       "\n",
       "       [[ 80.65589905]],\n",
       "\n",
       "       [[ 81.84587097]],\n",
       "\n",
       "       [[ 81.77168274]],\n",
       "\n",
       "       [[ 82.39753723]],\n",
       "\n",
       "       [[ 81.83576965]],\n",
       "\n",
       "       [[ 82.2009964 ]],\n",
       "\n",
       "       [[ 81.9990921 ]],\n",
       "\n",
       "       [[ 82.28163147]],\n",
       "\n",
       "       [[ 82.02549744]],\n",
       "\n",
       "       [[ 81.7735672 ]],\n",
       "\n",
       "       [[ 81.88449097]],\n",
       "\n",
       "       [[ 82.1120224 ]],\n",
       "\n",
       "       [[ 81.96757507]],\n",
       "\n",
       "       [[ 82.58985901]],\n",
       "\n",
       "       [[ 81.56919098]],\n",
       "\n",
       "       [[ 81.62623596]],\n",
       "\n",
       "       [[ 82.01275635]],\n",
       "\n",
       "       [[ 82.32814789]],\n",
       "\n",
       "       [[ 81.69210052]],\n",
       "\n",
       "       [[ 82.07037354]],\n",
       "\n",
       "       [[ 82.5898819 ]],\n",
       "\n",
       "       [[ 82.14924622]],\n",
       "\n",
       "       [[ 81.5790863 ]],\n",
       "\n",
       "       [[ 81.72783661]],\n",
       "\n",
       "       [[ 81.6434021 ]],\n",
       "\n",
       "       [[ 81.58794403]],\n",
       "\n",
       "       [[ 81.66473389]],\n",
       "\n",
       "       [[ 81.44605255]],\n",
       "\n",
       "       [[ 81.87219238]],\n",
       "\n",
       "       [[ 81.41608429]],\n",
       "\n",
       "       [[ 81.35622406]],\n",
       "\n",
       "       [[ 82.03117371]],\n",
       "\n",
       "       [[ 81.91287994]],\n",
       "\n",
       "       [[ 82.35823059]],\n",
       "\n",
       "       [[ 82.28265381]],\n",
       "\n",
       "       [[ 82.01786041]],\n",
       "\n",
       "       [[ 81.76685333]]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.reshape(-1)\n",
    "np.array(predict)*test_std[3]+test_mean[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
